from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import pandas as pd
import pickle
import re
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

# --- INITIALIZATION ---
app = FastAPI(title="TrendAI Final Backend", version="2.0")

# Download VADER lexicon for live sentiment (only runs once)
nltk.download('vader_lexicon', quiet=True)
sia = SentimentIntensityAnalyzer()

# Global variables for Data & Models
model = None
risk_df = None
narratives_df = None
trust_df = None

# --- LOAD RESOURCES ON STARTUP ---
@app.on_event("startup")
def load_resources():
    global model, risk_df, narratives_df, trust_df
    print("ðŸš€ Starting TrendAI Backend...")
    
    # 1. Load Bot Classifier Model
    try:
        with open('bot_detector.pkl', 'rb') as f:
            model = pickle.load(f)
        print("âœ… AI Model: Loaded (Bot Detector)")
    except Exception as e:
        print(f"âš ï¸ Warning: 'bot_detector.pkl' missing. Live analysis will fail.")

    # 2. Load Token Risk Data
    try:
        risk_df = pd.read_csv('final_risk_scores.csv') # Generated by risk_engine_v2.py
        print("âœ… Data: Token Risk Loaded")
    except:
        print("âš ï¸ Warning: 'final_risk_scores.csv' missing.")

    # 3. Load Narrative Risk Data
    try:
        narratives_df = pd.read_csv('final_narrative_risk.csv') # Generated by narrative_risk.py
        print("âœ… Data: Narrative Risk Loaded")
    except:
        print("âš ï¸ Warning: 'final_narrative_risk.csv' missing.")

    # 4. Load Account Trust Data
    try:
        trust_df = pd.read_csv('final_account_trust.csv') # Generated by account_trust.py
        print("âœ… Data: Account Trust Loaded")
    except:
        print("âš ï¸ Warning: 'final_account_trust.csv' missing.")

# --- HELPER FUNCTIONS ---
def clean_text(text):
    if not isinstance(text, str): return ""
    return re.sub(r'[^\w\s]', '', text.lower())

def analyze_sentiment(text):
    score = sia.polarity_scores(text)['compound']
    if score > 0.3: return "Positive", score
    if score < -0.3: return "Negative", score
    return "Neutral", score

# --- DATA MODELS ---
class TextPayload(BaseModel):
    text: str

# --- ENDPOINTS ---

@app.get("/")
def health_check():
    return {
        "status": "active",
        "modules": {
            "bot_detection": model is not None,
            "sentiment_engine": True,
            "risk_database": risk_df is not None
        }
    }

# --- 1. LIVE ANALYSIS (The "Magic" Endpoint) ---
@app.post("/analyze/live")
def live_analysis(payload: TextPayload):
    """
    Analyzes any text string for Bot Probability AND Sentiment.
    Useful for 'Check this post' feature on frontend.
    """
    if model is None:
        raise HTTPException(status_code=503, detail="AI Model not loaded")
    
    # 1. Bot Analysis
    clean = clean_text(payload.text)
    is_bot = model.predict([clean])[0]
    bot_prob = model.predict_proba([clean])[0][1]
    
    # 2. Sentiment Analysis
    sent_label, sent_score = analyze_sentiment(payload.text)
    
    # 3. Contextual Warning
    warning = "None"
    if is_bot == 1 and sent_label == "Positive":
        warning = "Artificial Hype (Possible Pump)"
    elif is_bot == 1 and sent_label == "Negative":
        warning = "Coordinated FUD Attack"
    
    return {
        "text": payload.text[:50] + "...",
        "ai_verdict": {
            "is_bot": bool(is_bot == 1),
            "bot_probability": float(round(bot_prob, 4)),
            "sentiment": sent_label,
            "sentiment_score": float(round(sent_score, 4))
        },
        "warning_label": warning
    }

# --- 2. TOKEN INTELLIGENCE ---
@app.get("/token/{token_id}")
def get_token_report(token_id: str):
    """
    Returns full risk profile + active narratives for a token.
    """
    token_id = token_id.upper()
    response = {"token": token_id}
    
    # Risk Profile
    if risk_df is not None:
        risk_row = risk_df[risk_df['token_id'] == token_id]
        if not risk_row.empty:
            response["risk_profile"] = risk_row.iloc[0].to_dict()
        else:
            response["risk_profile"] = "No Data"

    # Active Narratives
    if narratives_df is not None:
        nars = narratives_df[narratives_df['token_id'] == token_id]
        response["narratives"] = nars[['topic', 'risk_level', 'warning', 'bot_percentage']].to_dict(orient='records')
        
    return response

# --- 3. ACCOUNT TRUST CHECK ---
@app.get("/account/{username_or_id}")
def get_account_trust(username_or_id: str):
    """
    Checks if a specific user is trusted or a bot.
    """
    if trust_df is None:
        raise HTTPException(status_code=503, detail="Trust Database not loaded")
    
    # Search by ID or Username
    user = trust_df[
        (trust_df['account_id'] == username_or_id) | 
        (trust_df['username'] == username_or_id)
    ]
    
    if user.empty:
        raise HTTPException(status_code=404, detail="User not found")
    
    return user.iloc[0].to_dict()

# --- 4. DASHBOARD RANKINGS ---
@app.get("/rankings/high-risk")
def get_high_risk_tokens():
    if risk_df is None: return []
    return risk_df.head(5)[['token_id', 'risk_score', 'label', 'reason']].to_dict(orient='records')

@app.get("/rankings/bots")
def get_known_bots():
    """Returns top 10 worst offenders (lowest trust score)"""
    if trust_df is None: return []
    bots = trust_df.sort_values('trust_score', ascending=True).head(10)
    return bots[['username', 'trust_score', 'trust_label', 'bot_ratio']].to_dict(orient='records')